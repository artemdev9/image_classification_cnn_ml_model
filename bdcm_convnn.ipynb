{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Adapted from: https://keras.io/examples/vision/mnist_convnet/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIMsvaXx9c_h"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TiiNKWP79c_h"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dumch\\miniconda3\\Lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.18) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.ndimage import rotate, gaussian_filter\n",
    "import os\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKVD7w4u9c_i"
   },
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jR74eFKy9c_j",
    "outputId": "b4dc7e2d-016f-4888-d013-538a7286c29d"
   },
   "outputs": [],
   "source": [
    "# resize image\n",
    "def resize_image(image, target_size):\n",
    "    return cv2.resize(image, target_size)\n",
    "\n",
    "# normalise pixel values (0-1)\n",
    "def normalize_image(image):\n",
    "    return image / 255.0\n",
    "\n",
    "# data Augmentation \n",
    "def custom_augmentation(image):\n",
    "    # Rotate the image by 90, 180, 270 degrees\n",
    "    angle = random.choice([90, 180, 270])\n",
    "    image = rotate(image, angle, reshape=False, mode='nearest')\n",
    "\n",
    "    # Sharpen the image\n",
    "    if random.choice([True, False]):\n",
    "        kernel = np.array([[0, -1, 0], [-1, 5,-1], [0, -1, 0]])\n",
    "        image = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "    # Blur the image\n",
    "    if random.choice([True, False]):\n",
    "        image = gaussian_filter(image, sigma=1)\n",
    "\n",
    "    # Adjust Contrast\n",
    "    if random.choice([True, False]):\n",
    "        alpha = random.uniform(0.5, 1.5)\n",
    "        image = np.clip(alpha * image, 0, 255)\n",
    "\n",
    "    return image\n",
    "    \n",
    "\n",
    "def preprocess_image(image, target_size=(224, 224), augment=False):\n",
    "    image = resize_image(image, target_size)\n",
    "    if augment:\n",
    "        image = custom_augmentation(image)\n",
    "    image = normalize_image(image)\n",
    "    return image\n",
    "\n",
    "def preprocess_image_batch(input_dir, target_size=(224, 224), augmentation_prob=0.2):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(root, file)\n",
    "                image = cv2.imread(img_path)\n",
    "                if image is not None:\n",
    "                    augment = random.random() < augmentation_prob\n",
    "                    preprocessed_image = preprocess_image(image, target_size, augment)\n",
    "                    x_train.append(preprocessed_image)\n",
    "                    label = os.path.basename(root)\n",
    "                    y_train.append(label)\n",
    "    return np.array(x_train).astype(\"float32\"), np.array(y_train)\n",
    "\n",
    "input_dir = './images/bicycles'\n",
    "x_bicycles, y_bicycles = preprocess_image_batch(input_dir)\n",
    "\n",
    "input_dir = './images/cars'\n",
    "x_cars, y_cars = preprocess_image_batch(input_dir)\n",
    "\n",
    "input_dir = './images/deer'\n",
    "x_deer, y_deer = preprocess_image_batch(input_dir)\n",
    "\n",
    "input_dir = './images/mountains'\n",
    "x_mountains, y_mountains = preprocess_image_batch(input_dir)\n",
    "\n",
    "x_train = np.concatenate((x_bicycles, x_cars, x_deer, x_mountains), axis=0)\n",
    "y_train = np.concatenate((y_bicycles, y_cars, y_deer, y_mountains), axis=0)\n",
    "\n",
    "\n",
    "# xtest and ytest\n",
    "indices = np.random.choice(x_train.shape[0], 50, replace=False)\n",
    "\n",
    "# Creating the test dataset\n",
    "x_test = x_train[indices]\n",
    "y_test = y_train[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mclf()\n\u001b[1;32m----> 3\u001b[0m random_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(\u001b[43mx_train\u001b[49m), \u001b[38;5;241m9\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Plot the randomly selected images and their labels\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(random_indices):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "random_indices = np.random.choice(len(x_train), 9, replace=False)\n",
    "\n",
    "# Plot the randomly selected images and their labels\n",
    "for i, idx in enumerate(random_indices):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x_train[idx])\n",
    "    plt.title(y_train[idx][0])  \n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (7151, 224, 224, 3)\n",
      "7151 train samples\n",
      "50 test samples\n",
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# float64 to float32\n",
    "x_train = x_train.astype(\"float32\") \n",
    "x_test = x_test.astype(\"float32\") \n",
    "\n",
    "# Model parameters\n",
    "num_classes = 4\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder and transform the labels to integers\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)  # Use the same encoder for consistency\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train_categorical = to_categorical(y_train_encoded, num_classes)\n",
    "y_test_categorical = to_categorical(y_test_encoded, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR9v630T9c_j"
   },
   "source": [
    "# Build and Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ScM4WZ99c_j",
    "outputId": "0cca0082-ceb4-4c3e-e566-f8c9b6a900f8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(12, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.05),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.05),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.15),\n",
    "    layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10,  verbose=1, restore_best_weights=True )\n",
    "model.fit(x_train, y_train_categorical, batch_size=64, epochs=100, validation_split=0.15, shuffle=True, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7tslu089c_l"
   },
   "source": [
    "# Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fej44Szd9c_l",
    "outputId": "25536423-ca3c-46ca-8b64-2d1826fcdd02"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test_categorical, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[43mx_train\u001b[49m)\n\u001b[0;32m      2\u001b[0m image \u001b[38;5;241m=\u001b[39m x_train[index]\n\u001b[0;32m      3\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39mexpand_dims(image, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "index = np.random.randint(0, x_train)\n",
    "image = x_train[index]\n",
    "prediction = model.predict(np.expand_dims(image, axis=0))\n",
    "class_labels = ['bicycle', 'cars', 'deer', 'mountains']\n",
    "prediction_percentages = [value * 100 for value in prediction[0]]\n",
    "\n",
    "for label, percentage in zip(class_labels, prediction_percentages):\n",
    "    print(f\"{label}: {percentage:.2f}%\")\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "predicted_class = np.argmax(prediction, axis=1)\n",
    "predicted_label = label_encoder.inverse_transform(predicted_class)\n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mnist_convnet",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
